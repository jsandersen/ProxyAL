{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b339db0e-bc82-4578-8afd-885888085e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!pip install nltk\n",
    "#!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a22f209-0a26-40a3-b690-3bdaba282790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9724e995-64fd-4fbf-a7ed-4e5c62261eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load imdb data set ...\n"
     ]
    }
   ],
   "source": [
    "data_set = 'imdb'\n",
    "\n",
    "print('Load %s data set ...' % data_set)\n",
    "data_X = np.load('./../data/datasets/%s_X.npy' % data_set)\n",
    "y = np.load('./../data/datasets/%s_y.npy' % data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b046795-b34b-497c-a092-cba0a0982f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Soul Calibur is more solid than it ever was... with the new character creation, and the bad-ass chronicle of the sword mode on the home version.The arcade version is more complete, even though the character roster is smaller than the home version, this version is definitely the more pretty of the two, eliminating all of the \"goofy/unrealistic\" fighting styles found in the home version. If you were in any way disappointed with the home version, or perhaps thought it was \"too much,\" you might find a much more likable and straight forward game of Soul Calibur in the arcade. Think you have what it takes to become a Legend?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fccf40ef-a094-40f5-a9f7-c152be09618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a582f91-21fb-4432-8f8b-8b0de8aaa1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPLIST = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76036dc7-d447-4d70-9edc-f98a3fae3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\",\"''\"]\n",
    "\n",
    "def tokenizeText(text):\n",
    "    \n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = text.lower()\n",
    "    \n",
    "    tokens = nlp(text)\n",
    "    \n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "    \n",
    "    tokens = [tok for tok in tokens if tok.lower() not in STOPLIST]\n",
    "    \n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "    tokens = [tok for tok in tokens if len(tok) >= 3]\n",
    "    tokens = [tok for tok in tokens if tok.isalpha()]\n",
    "    \n",
    "    #tokens = list(set(tokens))\n",
    "    tokens = list((tokens))\n",
    "    \n",
    "    return ' '.join(tokens[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6151047d-827a-43ad-8a49-901c7dd16b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66c85f03cf44da69dfc6c1945f0acf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import notebook\n",
    "X_clean = [tokenizeText(x) for x in notebook.tqdm(data_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e76d6404-db9c-40c2-abed-bfc2503642ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_clean_imdb', X_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "91b4dfd4-001e-4bc2-9360-21aed6ca836d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soul calibur solid ever new character creation bad ass chronicle sword mode home arcade version complete even though character roster small home version version definitely pretty two eliminate goofy unrealistic fight style find home version way disappointed home version perhaps think much might find much likable straight forward game soul calibur arcade think take become legend'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c4a9f12-ac96-4bf7-8ae1-40d0e6d2852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "718ae556-3350-4b49-98ba-f8bd11b32e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 5000\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "694921e4-8d36-4710-923f-2575bcd5d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def get_data():\n",
    "    \n",
    "    x_index = [i for i in range(len(X_clean))]\n",
    "    X_train_index, X_test_index, y_train, y_test = train_test_split(x_index, y, test_size=0.5, random_state=42, stratify=y)\n",
    "    X_train = np.array([X_clean[i] for i in X_train_index])\n",
    "    X_test = np.array([X_clean[i] for i in X_test_index])\n",
    "    \n",
    "    tokenizer.fit_on_texts(X_train) \n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    X_pool = X_train\n",
    "    y_pool = y_train\n",
    "\n",
    "    return X_pool, y_pool, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8996a552-eab2-4987-b2b4-7c0d93516612",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pool, y_pool, X_test, y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7617e376-717b-4dab-b910-dd4395f66d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = 1\n",
    "max_features = 5000\n",
    "maxlen = 400\n",
    "batch_size = 6\n",
    "embedding_dims = 50\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "020f9680-2381-4613-b5d6-c526c612467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)...\n",
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "print('Pad sequences (samples x time)...')\n",
    "X_pool = sequence.pad_sequences(X_pool, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('x_train shape:', X_pool.shape)\n",
    "print('x_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "034ca358-8ad1-4ef3-9a49-1ca700b77772",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "\n",
    "class FastText(Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 maxlen,\n",
    "                 max_features,\n",
    "                 embedding_dims,\n",
    "                 class_num=2,\n",
    "                 last_activation='softmax'):\n",
    "        super(FastText, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.max_features = max_features\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.class_num = class_num\n",
    "        self.last_activation = last_activation\n",
    "        self.embedding = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen)\n",
    "        self.avg_pooling = GlobalAveragePooling1D()\n",
    "        self.classifier = Dense(self.class_num, activation=self.last_activation)\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if len(inputs.get_shape()) != 2:\n",
    "            raise ValueError('The rank of inputs of FastText must be 2, but now is %d' % len(inputs.get_shape()))\n",
    "        if inputs.get_shape()[1] != self.maxlen:\n",
    "            raise ValueError('The maxlen of inputs of FastText must be %d, but now is %d' % (self.maxlen, inputs.get_shape()[1]))\n",
    "        embedding = self.embedding(inputs)\n",
    "        x = self.avg_pooling(embedding)\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31586d-d72b-4c42-83b5-3d9b524c4338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0d6654d-fffa-477e-bc0d-671e4a8ff61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pool = np.array(y_pool)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e30b3fdb-392b-47b1-a82a-ce3af41720b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_pool = to_categorical(y_pool)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb39366-06a6-4ac5-9127-9253f7d2cb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "14b00e43-3f92-4a01-871d-afae0ff61123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.6926 - accuracy: 0.5100 - val_loss: 0.6910 - val_accuracy: 0.6140\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.6868 - accuracy: 0.5620 - val_loss: 0.6879 - val_accuracy: 0.6580\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.6800 - val_loss: 0.6827 - val_accuracy: 0.7780\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.6632 - accuracy: 0.7160 - val_loss: 0.6741 - val_accuracy: 0.7400\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.8300 - val_loss: 0.6629 - val_accuracy: 0.5840\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.6067 - accuracy: 0.8120 - val_loss: 0.6482 - val_accuracy: 0.6340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0634088880>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FastText(maxlen, max_features, embedding_dims, class_num=2)\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "n = 500\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, mode='max')\n",
    "model.fit(X_pool[:n], y_pool[:n],\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(X_test[:n], y_test[:n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b5f96-27a4-4d6c-80c2-1834734980cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa04852-a691-41a5-853f-4a0b44a01af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
